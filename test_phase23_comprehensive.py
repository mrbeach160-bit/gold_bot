# test_phase23_comprehensive.py
"""
Comprehensive test for Phase 2 & 3 Advanced AI Model Enhancement.
Tests all new features including advanced feature engineering, enhanced models,
dynamic ensemble, and evaluation framework.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sys
import os

# Add project root to path
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def create_comprehensive_test_data(samples: int = 200) -> pd.DataFrame:
    """Create realistic test data for comprehensive testing."""
    print(f"Creating comprehensive test data with {samples} samples...")
    
    # Create time series with realistic price movements
    start_date = datetime.now() - timedelta(days=samples//48)  # Assuming 5-minute data
    dates = pd.date_range(start=start_date, periods=samples, freq='5min')
    
    # Generate realistic OHLCV data with some trends and volatility
    np.random.seed(42)  # For reproducible tests
    
    # Base price with trend
    base_price = 2000
    trend = np.linspace(0, 100, samples)  # Upward trend
    noise = np.cumsum(np.random.normal(0, 5, samples))  # Random walk
    
    close_prices = base_price + trend + noise
    
    # Generate OHLCV from close prices
    data = []
    for i, close in enumerate(close_prices):
        if i == 0:
            open_price = close
        else:
            open_price = close_prices[i-1]
        
        # High and low with some randomness
        high = close + abs(np.random.normal(2, 1))
        low = close - abs(np.random.normal(2, 1))
        
        # Ensure OHLC consistency
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        volume = max(100, np.random.normal(1000, 300))
        
        data.append({
            'datetime': dates[i],
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': volume
        })
    
    df = pd.DataFrame(data)
    df.set_index('datetime', inplace=True)
    
    print(f"‚úÖ Created test data: {len(df)} samples from {df.index[0]} to {df.index[-1]}")
    return df

def test_advanced_features():
    """Test Phase 2 advanced feature engineering."""
    print("\n" + "="*70)
    print("PHASE 2 TESTING: ADVANCED FEATURE ENGINEERING")
    print("="*70)
    
    from models.advanced_features import AdvancedDataPipeline
    from models.advanced_indicators import EnhancedIndicators
    
    # Create test data
    test_data = create_comprehensive_test_data(150)
    
    print("\nüîç Testing Advanced Feature Pipeline...")
    try:
        feature_pipeline = AdvancedDataPipeline('5m')
        enhanced_data = feature_pipeline.transform(test_data.copy())
        
        original_features = test_data.shape[1]
        enhanced_features = enhanced_data.shape[1]
        new_features = enhanced_features - original_features
        
        print(f"‚úÖ Advanced features: {original_features} ‚Üí {enhanced_features} (+{new_features} features)")
        print(f"   Multi-timeframe, volatility, S/R, seasonality, regime features added")
        
    except Exception as e:
        print(f"‚ùå Advanced features error: {e}")
        return False
    
    print("\nüîç Testing Enhanced Technical Indicators...")
    try:
        indicator_calculator = EnhancedIndicators()
        indicator_data = indicator_calculator.add_all_indicators(test_data.copy())
        
        original_features = test_data.shape[1]
        indicator_features = indicator_data.shape[1]
        new_indicators = indicator_features - original_features
        
        print(f"‚úÖ Enhanced indicators: {original_features} ‚Üí {indicator_features} (+{new_indicators} indicators)")
        print(f"   Advanced RSI, MACD, Bollinger, Stochastic, ADX, Volume indicators added")
        
    except Exception as e:
        print(f"‚ùå Enhanced indicators error: {e}")
        return False
    
    return True

def test_advanced_models():
    """Test Phase 2 advanced model architectures."""
    print("\n" + "="*70)
    print("PHASE 2 TESTING: ADVANCED MODEL ARCHITECTURES")
    print("="*70)
    
    from models import create_model
    
    test_data = create_comprehensive_test_data(100)
    
    # Test Advanced LSTM with attention
    print("\nüîç Testing Advanced LSTM with Attention...")
    try:
        lstm_model = create_model('lstm', 'XAU/USD', '5m')
        print(f"‚úÖ Advanced LSTM created: {lstm_model.__class__.__name__}")
        print(f"   Features: Attention mechanism, multivariate inputs, multi-class output")
        
        # Test training (quick test with small data)
        training_success = lstm_model.train(test_data)
        if training_success:
            print("‚úÖ Advanced LSTM training completed successfully")
        else:
            print("‚ö†Ô∏è  Advanced LSTM training skipped (insufficient data for full test)")
            
    except Exception as e:
        print(f"‚ùå Advanced LSTM error: {e}")
        return False
    
    # Test Random Forest
    print("\nüîç Testing Random Forest Model...")
    try:
        rf_model = create_model('randomforest', 'XAU/USD', '5m')
        print(f"‚úÖ Random Forest created: {rf_model.__class__.__name__}")
        
        training_success = rf_model.train(test_data)
        if training_success:
            print("‚úÖ Random Forest training completed")
            
            # Test prediction
            prediction = rf_model.predict(test_data)
            print(f"‚úÖ Random Forest prediction: {prediction['direction']} (confidence: {prediction['confidence']:.3f})")
        else:
            print("‚ö†Ô∏è  Random Forest training skipped (insufficient data)")
            
    except Exception as e:
        print(f"‚ùå Random Forest error: {e}")
        return False
    
    # Test SVM
    print("\nüîç Testing SVM Model...")
    try:
        svm_model = create_model('svm', 'XAU/USD', '5m')
        print(f"‚úÖ SVM created: {svm_model.__class__.__name__}")
        
        training_success = svm_model.train(test_data)
        if training_success:
            print("‚úÖ SVM training completed")
            
            # Test prediction
            prediction = svm_model.predict(test_data)
            print(f"‚úÖ SVM prediction: {prediction['direction']} (confidence: {prediction['confidence']:.3f})")
        else:
            print("‚ö†Ô∏è  SVM training skipped (insufficient data)")
            
    except Exception as e:
        print(f"‚ùå SVM error: {e}")
        return False
    
    return True

def test_dynamic_ensemble():
    """Test Phase 3 dynamic ensemble system."""
    print("\n" + "="*70)
    print("PHASE 3 TESTING: DYNAMIC ENSEMBLE & META-LEARNING")
    print("="*70)
    
    from models.advanced_ensemble import DynamicEnsemble, PerformanceTracker, RegimeDetector
    from models import create_model
    
    test_data = create_comprehensive_test_data(120)
    
    print("\nüîç Testing Performance Tracker...")
    try:
        perf_tracker = PerformanceTracker()
        
        # Simulate some performance updates
        for i in range(10):
            mock_prediction = {'direction': 'BUY', 'confidence': 0.7}
            actual = 'BUY' if i % 3 == 0 else 'SELL'  # Mixed results
            perf_tracker.update_performance('test_model', mock_prediction, actual)
        
        performance = perf_tracker.get_recent_performance('test_model')
        weights = perf_tracker.calculate_dynamic_weights(['test_model', 'another_model'])
        
        print(f"‚úÖ Performance Tracker working")
        print(f"   Recent performance: {performance:.3f}")
        print(f"   Dynamic weights: {weights}")
        
    except Exception as e:
        print(f"‚ùå Performance Tracker error: {e}")
        return False
    
    print("\nüîç Testing Regime Detector...")
    try:
        regime_detector = RegimeDetector()
        current_regime = regime_detector.detect_regime(test_data)
        regime_preferences = regime_detector.get_regime_model_preferences(current_regime)
        
        print(f"‚úÖ Regime Detector working")
        print(f"   Current regime: {current_regime}")
        print(f"   Model preferences: {list(regime_preferences.keys())}")
        
    except Exception as e:
        print(f"‚ùå Regime Detector error: {e}")
        return False
    
    print("\nüîç Testing Dynamic Ensemble...")
    try:
        dynamic_ensemble = DynamicEnsemble('XAU/USD', '5m')
        
        # Create and add some base models
        models_to_add = ['lightgbm', 'xgboost']
        for model_type in models_to_add:
            try:
                model = create_model(model_type, 'XAU/USD', '5m')
                if model.train(test_data):
                    dynamic_ensemble.add_model(model)
                    print(f"‚úÖ Added {model_type} to dynamic ensemble")
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not add {model_type}: {e}")
        
        # Test dynamic ensemble training
        training_success = dynamic_ensemble.train(test_data)
        if training_success:
            print("‚úÖ Dynamic ensemble training completed")
            
            # Test prediction
            prediction = dynamic_ensemble.predict(test_data)
            print(f"‚úÖ Dynamic ensemble prediction: {prediction['direction']} (confidence: {prediction['confidence']:.3f})")
            if 'regime' in prediction:
                print(f"   Market regime: {prediction['regime']}")
            if 'consensus_info' in prediction:
                print(f"   Agreement score: {prediction['consensus_info'].get('agreement_score', 'N/A')}")
                
        else:
            print("‚ö†Ô∏è  Dynamic ensemble training incomplete")
            
    except Exception as e:
        print(f"‚ùå Dynamic Ensemble error: {e}")
        return False
    
    return True

def test_evaluation_framework():
    """Test Phase 3 evaluation framework."""
    print("\n" + "="*70)
    print("PHASE 3 TESTING: EVALUATION & TRADING SIMULATION")
    print("="*70)
    
    from models.evaluation import TradingSimulator, ComprehensiveEvaluator
    from models import create_model
    
    test_data = create_comprehensive_test_data(100)
    
    print("\nüîç Testing Trading Simulator...")
    try:
        simulator = TradingSimulator(initial_capital=10000)
        
        # Generate some mock predictions
        mock_predictions = []
        for i in range(20):
            direction = np.random.choice(['BUY', 'SELL', 'HOLD'], p=[0.3, 0.3, 0.4])
            confidence = np.random.uniform(0.5, 0.9) if direction != 'HOLD' else 0.5
            mock_predictions.append({
                'direction': direction,
                'confidence': confidence
            })
        
        # Run backtest
        results = simulator.backtest(mock_predictions, test_data.tail(20))
        
        print(f"‚úÖ Trading Simulator working")
        print(f"   Total return: {results.get('total_return', 0):.3f}")
        print(f"   Sharpe ratio: {results.get('sharpe_ratio', 0):.3f}")
        print(f"   Max drawdown: {results.get('max_drawdown', 0):.3f}")
        print(f"   Total trades: {results.get('total_trades', 0)}")
        
    except Exception as e:
        print(f"‚ùå Trading Simulator error: {e}")
        return False
    
    print("\nüîç Testing Comprehensive Evaluator...")
    try:
        evaluator = ComprehensiveEvaluator()
        
        # Create a simple model for evaluation
        model = create_model('lightgbm', 'XAU/USD', '5m')
        if model.train(test_data):
            eval_results = evaluator.evaluate_model(model, test_data, comprehensive=False)
            
            print(f"‚úÖ Comprehensive Evaluator working")
            if 'basic_metrics' in eval_results:
                print(f"   Accuracy: {eval_results['basic_metrics'].get('accuracy', 0):.3f}")
            if 'trading_simulation' in eval_results:
                trading_metrics = eval_results['trading_simulation']
                print(f"   Trading return: {trading_metrics.get('total_return', 0):.3f}")
        else:
            print("‚ö†Ô∏è  Model training failed, evaluation skipped")
            
    except Exception as e:
        print(f"‚ùå Comprehensive Evaluator error: {e}")
        return False
    
    return True

def test_enhanced_model_manager():
    """Test enhanced ModelManager with all new features."""
    print("\n" + "="*70)
    print("PHASE 2 & 3 TESTING: ENHANCED MODEL MANAGER")
    print("="*70)
    
    from models import ModelManager
    
    test_data = create_comprehensive_test_data(80)
    
    print("\nüîç Testing Enhanced ModelManager...")
    try:
        # Create manager with advanced configuration
        manager = ModelManager('XAU/USD', '5m')
        
        print(f"‚úÖ Enhanced ModelManager created")
        print(f"   Individual models: {list(manager.models.keys())}")
        print(f"   Ensemble models: {list(manager.ensemble_models.keys())}")
        
        # Test training
        print(f"\nüîß Training models...")
        training_results = manager.train_all_models(test_data)
        
        successful_models = [name for name, success in training_results.items() if success]
        print(f"‚úÖ Successfully trained: {successful_models}")
        
        if successful_models:
            # Test predictions
            print(f"\nüîÆ Getting predictions...")
            predictions = manager.get_predictions(test_data)
            
            for model_name, pred in predictions.items():
                if 'error' not in pred:
                    print(f"   {model_name}: {pred['direction']} (conf: {pred['confidence']:.3f})")
            
            # Test ensemble prediction
            ensemble_pred = manager.get_ensemble_prediction(test_data)
            print(f"‚úÖ Ensemble: {ensemble_pred['direction']} (conf: {ensemble_pred['confidence']:.3f})")
            
            # Test dynamic ensemble setup
            if manager.setup_dynamic_ensemble():
                print("‚úÖ Dynamic ensemble setup successful")
                
                dynamic_pred = manager.get_ensemble_prediction(test_data, method='dynamic_ensemble')
                print(f"‚úÖ Dynamic ensemble: {dynamic_pred['direction']} (conf: {dynamic_pred['confidence']:.3f})")
            
            # Test multi-horizon predictions
            multi_horizon = manager.get_multi_horizon_predictions(test_data, horizons=[5, 20])
            print(f"‚úÖ Multi-horizon predictions generated for {len(multi_horizon)} horizons")
            
        else:
            print("‚ö†Ô∏è  No models trained successfully")
        
    except Exception as e:
        print(f"‚ùå Enhanced ModelManager error: {e}")
        return False
    
    return True

def run_comprehensive_tests():
    """Run all comprehensive tests for Phase 2 & 3."""
    print("="*80)
    print("COMPREHENSIVE TESTING: PHASE 2 & 3 ADVANCED AI MODEL ENHANCEMENT")
    print("="*80)
    
    all_tests_passed = True
    
    # Test Phase 2 features
    if test_advanced_features():
        print("\n‚úÖ PHASE 2 FEATURE ENGINEERING: PASSED")
    else:
        print("\n‚ùå PHASE 2 FEATURE ENGINEERING: FAILED")
        all_tests_passed = False
    
    if test_advanced_models():
        print("\n‚úÖ PHASE 2 MODEL ARCHITECTURES: PASSED")
    else:
        print("\n‚ùå PHASE 2 MODEL ARCHITECTURES: FAILED")
        all_tests_passed = False
    
    # Test Phase 3 features
    if test_dynamic_ensemble():
        print("\n‚úÖ PHASE 3 DYNAMIC ENSEMBLE: PASSED")
    else:
        print("\n‚ùå PHASE 3 DYNAMIC ENSEMBLE: FAILED")
        all_tests_passed = False
    
    if test_evaluation_framework():
        print("\n‚úÖ PHASE 3 EVALUATION FRAMEWORK: PASSED")
    else:
        print("\n‚ùå PHASE 3 EVALUATION FRAMEWORK: FAILED")
        all_tests_passed = False
    
    # Test integrated system
    if test_enhanced_model_manager():
        print("\n‚úÖ ENHANCED MODEL MANAGER: PASSED")
    else:
        print("\n‚ùå ENHANCED MODEL MANAGER: FAILED")
        all_tests_passed = False
    
    # Final results
    print("\n" + "="*80)
    print("COMPREHENSIVE TEST RESULTS")
    print("="*80)
    
    if all_tests_passed:
        print("üéâ ALL TESTS PASSED!")
        print("\n‚úÖ Phase 2 & 3 Implementation Successfully Completed:")
        print("   ‚Ä¢ Advanced feature engineering with multi-timeframe analysis")
        print("   ‚Ä¢ Enhanced technical indicators with 40+ features")
        print("   ‚Ä¢ Advanced LSTM with attention mechanism")
        print("   ‚Ä¢ Random Forest and SVM models for ensemble diversity")
        print("   ‚Ä¢ Dynamic ensemble with performance-based weighting")
        print("   ‚Ä¢ Regime-aware model selection")
        print("   ‚Ä¢ Consensus analysis and uncertainty quantification")
        print("   ‚Ä¢ Comprehensive evaluation with trading simulation")
        print("   ‚Ä¢ Multi-horizon predictions")
        print("   ‚Ä¢ Production-ready ensemble manager")
        
        print("\nüöÄ The Gold Bot now has state-of-the-art AI capabilities!")
        
    else:
        print("‚ùå SOME TESTS FAILED")
        print("Please review the errors above and fix any issues.")
    
    return all_tests_passed

if __name__ == "__main__":
    success = run_comprehensive_tests()
    exit(0 if success else 1)